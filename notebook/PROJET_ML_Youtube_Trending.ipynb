{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f478863d",
   "metadata": {},
   "source": [
    "# PROJET ML — CLASSIFICATION DE VIDÉOS YOUTUBE *TRENDING*\n",
    "\n",
    "**Dataset Kaggle**: https://www.kaggle.com/datasets/datasnaek/youtube-new\n",
    "\n",
    "**Objectif**: Développer un classificateur pour prédire si une vidéo YouTube deviendra *trending*.\n",
    "\n",
    "> Ce notebook est conçu pour être complété. Chaque section contient des consignes détaillées et des zones de code à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546bd156",
   "metadata": {},
   "source": [
    "## 1. Importation des librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5e9d0",
   "metadata": {},
   "source": [
    "**Consigne 1.1 — Importez toutes les librairies nécessaires**\n",
    "- `pandas`, `numpy` pour la manipulation de données  \n",
    "- `matplotlib.pyplot`, `seaborn` pour la visualisation  \n",
    "- `sklearn` pour le machine learning  \n",
    "- `warnings` pour supprimer les avertissements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2ef50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kirill\n"
     ]
    }
   ],
   "source": [
    "# VOTRE CODE ICI - Section 1.1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "# Suppression des warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Kirill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879269a0",
   "metadata": {},
   "source": [
    "## 2. Chargement et exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a658e0",
   "metadata": {},
   "source": [
    "**Consigne 2.1 — Chargement des données**\n",
    "- Chargez le fichier `USvideos.csv` avec pandas  \n",
    "- Affichez les 5 premières lignes  \n",
    "- Affichez les informations générales (`info()`, `shape`, `describe()`)\n",
    "\n",
    "*Aide* :\n",
    "- Utilisez `pd.read_csv()` avec `encoding='utf-8'`\n",
    "- `.info()` donne les types de colonnes et valeurs non-nulles\n",
    "- `.describe()` donne les statistiques descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21041baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'archive/USvideos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# VOTRE CODE ICI - Section 2.1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43marchive/USvideos.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPremières lignes: \u001b[39m\u001b[33m\"\u001b[39m, df.head())\n\u001b[32m      5\u001b[39m display(df())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/youtube-popularity-ml/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/youtube-popularity-ml/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/youtube-popularity-ml/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/youtube-popularity-ml/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/youtube-popularity-ml/.venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'archive/USvideos.csv'"
     ]
    }
   ],
   "source": [
    "# VOTRE CODE ICI - Section 2.1\n",
    "\n",
    "df = pd.read_csv('archive/USvideos.csv', encoding='utf-8')\n",
    "print(\"Premières lignes: \", df.head())\n",
    "display(df())\n",
    "print(\"\\nInformations générales:\", df.info())\n",
    "display(...())\n",
    "print(\"Shape:\",)\n",
    "display(df.describe(include='all').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03a263",
   "metadata": {},
   "source": [
    "**Consigne 2.2 — Analyse des valeurs manquantes**  \n",
    "- Comptez les valeurs manquantes par colonne  \n",
    "- Identifiez les colonnes avec le plus de valeurs manquantes  \n",
    "- Affichez le pourcentage de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 2.2\n",
    "# missing = df...\n",
    "# pct_missing = (missing / len(df)) * 100\n",
    "# print(\"Valeurs manquantes (nombre):\")\n",
    "# display(....))\n",
    "# print(\"\\nValeurs manquantes (pourcentage):\")\n",
    "# display(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43660bf",
   "metadata": {},
   "source": [
    "**Consigne 2.3 — Exploration des catégories**  \n",
    "- Chargez le fichier JSON des catégories (`US_category_id.json`)  \n",
    "- Fusionnez avec le DataFrame principal  \n",
    "- Affichez la distribution des catégories\n",
    "\n",
    "*Aide* : La structure JSON est du type:  \n",
    "`{\"items\": [{\"id\": \"1\", \"snippet\": {\"title\": \"Film & Animation\"}}, ...]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53717a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 2.3\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# categories_raw = read-json...\n",
    "# items = categories_raw['items'].tolist()\n",
    "# category_dict = {int(item['id']): item['snippet']['title'] for item in items}\n",
    "# cat_df = pd.DataFrame(list(category_dict.items()), columns=['category_id', 'category_title'])\n",
    "# df_merged = df.merge(cat_df, how='left', left_on='category_id', right_on='category_id')\n",
    "# print(\"Distribution des catégories:\")\n",
    "# display(df_merged['category_title'].value_counts().to_frame('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86ba1a",
   "metadata": {},
   "source": [
    "## 3. Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981825a0",
   "metadata": {},
   "source": [
    "**Consigne 3.1 — Nettoyage des données**\n",
    "- Supprimez les doublons basés sur `video_id`  \n",
    "- Gérez les valeurs manquantes dans `description` (remplacez par string vide)  \n",
    "- Convertissez `publish_time` en datetime  \n",
    "- Supprimez les lignes avec des valeurs aberrantes (ex: `views` négatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 3.1\n",
    "# df_clean = df.drop_duplicates(subset='video_id').copy()\n",
    "# df_clean['description'] = ....\n",
    "# import pandas as pd\n",
    "# df_clean['publish_time'] = ().... errors='coerce')\n",
    "# df_clean = df_clean[(df_clean['views'] >= 0) & (df_clean['likes'] >= 0) & (df_clean['dislikes'] >= 0) & (df_clean['comment_count'] >= 0)]\n",
    "# df_clean = df_clean.dropna(subset=['publish_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c110ca",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ce78b",
   "metadata": {},
   "source": [
    "**Consigne 4.1 — Variables d'engagement**\n",
    "** définition : https://support.google.com/youtube/answer/2991785?hl=fr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab13049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 4.1\n",
    "# import numpy as np\n",
    "# eps = 1e-9\n",
    "# denom = df_clean['likes'] + df_clean['dislikes']\n",
    "# df_clean['like_ratio'] = np.where(denom > 0, df_clean['likes'] / denom, 0)\n",
    "# df_clean['engagement_rate'] = np.where(df_clean['views'] > 0,\n",
    "#                                        (df_clean['likes'] + df_clean['dislikes'] + df_clean['comment_count']) / (df_clean['views'] + eps),\n",
    "#                                        0)\n",
    "# df_clean['comments_per_view'] = np.where(df_clean['views'] > 0, df_clean['comment_count'] / (df_clean['views'] + eps), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ad347",
   "metadata": {},
   "source": [
    "**Consigne 4.2 — Variables temporelles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 4.2\n",
    "# df_clean['publish_hour'] = ....\n",
    "# df_clean['publish_day_of_week'] = ...\n",
    "# df_clean['publish_month'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252ebee",
   "metadata": {},
   "source": [
    "**Consigne 4.3 — Variables textuelles (titre)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ebdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 4.3\n",
    "# df_clean['title_length'] = ...\n",
    "# df_clean['title_word_count'] = ....\n",
    "# df_clean['has_caps'] = ...\n",
    "# df_clean['has_numbers'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7eb43",
   "metadata": {},
   "source": [
    "## 5. Création de la variable cible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad73d8",
   "metadata": {},
   "source": [
    "**Consigne 5.1 — Définition de `is_trending`**  \n",
    "- Une vidéo est *trending* si elle a plus de vues que le 80e percentile de sa catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbcd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 5.1\n",
    "# df_clean['is_trending'] = (df_clean.groupby('category_id')['views']\n",
    "#                                   .transform(lambda x: x > x.quantile(0.8))).astype(int)\n",
    "# print(\"Distribution de la variable cible:\")\n",
    "# display(df_clean['is_trending'].value_counts().to_frame('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac7477",
   "metadata": {},
   "source": [
    "## 6. Préparation des données pour l'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828d672c",
   "metadata": {},
   "source": [
    "**Consignes 6.1 & 6.2 — Sélection des features & split train/test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 6.1 et 6.2\n",
    "# features = ['views', 'likes', 'dislikes', 'comment_count',\n",
    "#             'like_ratio', 'engagement_rate', 'title_length', 'publish_hour', 'category_id']\n",
    "# X = df_clean[features].copy()\n",
    "# y = df_clean['is_trending'].copy()\n",
    "#.......\n",
    "# ......\n",
    "\n",
    "# print(f\"Taille train: {X_train.shape}\")\n",
    "# print(f\"Taille test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9f34b",
   "metadata": {},
   "source": [
    "**Consigne 6.3 — Normalisation des données (StandardScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 6.3\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# num_cols = ['views', 'likes', 'dislikes', 'comment_count', 'like_ratio', 'engagement_rate', 'title_length', 'publish_hour']\n",
    "# # Fit uniquement sur train\n",
    "# ....\n",
    "# ...\n",
    "# ....\n",
    "# ....\n",
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27586c4a",
   "metadata": {},
   "source": [
    "## 7. Modèle 1 — Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc20f6b",
   "metadata": {},
   "source": [
    "**Consigne 7.1 — Entraînement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd08b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 7.1\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# ....\n",
    "# ....\n",
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee70bbb",
   "metadata": {},
   "source": [
    "**Consigne 7.2 — Évaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 7.2\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# print(\"Random Forest - Résultats:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, rf_predictions):.4f}\")\n",
    "# print(f\"Precision: {precision_score(y_test, rf_predictions):.4f}\")\n",
    "# print(f\"Recall: {recall_score(y_test, rf_predictions):.4f}\")\n",
    "# print(f\"F1-Score: {f1_score(y_test, rf_predictions):.4f}\")\n",
    "# # Importance des variables\n",
    "# import pandas as pd\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'feature': X.columns,\n",
    "#     'importance': rf_model.feature_importances_\n",
    "# }).sort_values('importance', ascending=False)\n",
    "# print(\"\\nTop 10 variables importantes:\")\n",
    "# display(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd0a5c",
   "metadata": {},
   "source": [
    "## 8. Modèle 2 — Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad95c6",
   "metadata": {},
   "source": [
    "**Consigne 8.1 — Entraînement (utiliser données normalisées)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bf04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 8.1\n",
    "# from sklearn.svm import SVC\n",
    "# ...\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a3ce6",
   "metadata": {},
   "source": [
    "**Consigne 8.2 — Évaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d067ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 8.2\n",
    "# print(\"SVM - Résultats:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, svm_predictions):.4f}\")\n",
    "#....\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4372dac",
   "metadata": {},
   "source": [
    "## 9. Modèle 3 — Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c3bfd",
   "metadata": {},
   "source": [
    "**Consigne 9.1 — Entraînement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 9.1\n",
    "# try:\n",
    "#     from xgboost import XGBClassifier\n",
    "#     xgb_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, subsample=1.0, colsample_bytree=1.0, random_state=42, n_jobs=-1, eval_metric='logloss')\n",
    "#     xgb_model.fit(X_train, y_train)\n",
    "#     xgb_predictions = xgb_model.predict(X_test)\n",
    "# except ImportError:\n",
    "#     print(\"XGBoost n'est pas installé. Installez avec: pip install xgboost\")\n",
    "#     xgb_model = None\n",
    "#     xgb_predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9311d79",
   "metadata": {},
   "source": [
    "**Consigne 9.2 — Évaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462bb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 9.2\n",
    "# if xgb_predictions is not None:\n",
    "#     print(\"XGBoost - Résultats:\")\n",
    "#     print(f\"Accuracy: {accuracy_score(y_test, xgb_predictions):.4f}\")\n",
    "#     print(f\"Precision: {precision_score(y_test, xgb_predictions):.4f}\")\n",
    "#     print(f\"Recall: {recall_score(y_test, xgb_predictions):.4f}\")\n",
    "#     print(f\"F1-Score: {f1_score(y_test, xgb_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11ab75",
   "metadata": {},
   "source": [
    "## 10. Modèle 4 — Réseau de Neurones (MLPClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346cba0",
   "metadata": {},
   "source": [
    "**Consigne 10.1 — Entraînement (données normalisées)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c15608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 10.1\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "# nn_model.fit(X_train_scaled, y_train)\n",
    "# nn_predictions = nn_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77af7a2",
   "metadata": {},
   "source": [
    "**Consigne 10.2 — Évaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 10.2\n",
    "# print(\"Réseau de Neurones - Résultats:\")\n",
    "# ....\n",
    "# print(f\"Precision: {precision_score(y_test, nn_predictions):.4f}\")\n",
    "# print(f\"Recall: {recall_score(y_test, nn_predictions):.4f}\")\n",
    "# print(f\"F1-Score: {f1_score(y_test, nn_predictions):.4f}\")\n",
    "# # Nombre d'itérations\n",
    "# # ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc77978",
   "metadata": {},
   "source": [
    "## 11. Comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 11.1\n",
    "# import pandas as pd\n",
    "# results = []\n",
    "# # Remplir en fonction des métriques calculées plus haut\n",
    "# # results.append({'Model': 'Random Forest', 'Accuracy': ..., 'Precision': ..., 'Recall': ..., 'F1-Score': ...})\n",
    "# # results.append({'Model': 'SVM', 'Accuracy': ..., 'Precision': ..., 'Recall': ..., 'F1-Score': ...})\n",
    "# # if xgb_predictions is not None: results.append({'Model': 'XGBoost', 'Accuracy': ..., 'Precision': ..., 'Recall': ..., 'F1-Score': ...})\n",
    "# # results.append({'Model': 'Neural Network', 'Accuracy': ..., 'Precision': ..., 'Recall': ..., 'F1-Score': ...})\n",
    "# results_df = pd.DataFrame(results)\n",
    "# display(results_df)\n",
    "# # Graphique comparatif des F1-scores (optionnel)\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # plt.figure()\n",
    "# # plt.bar(results_df['Model'], results_df['F1-Score'])\n",
    "# # plt.title('Comparaison des F1-scores')\n",
    "# # plt.ylabel('F1-Score')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb2a166",
   "metadata": {},
   "source": [
    "## 12. Validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac69276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 12.1\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# # Exemple avec Random Forest (remplacez par votre meilleur modèle)\n",
    "# # scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
    "# # print(f\"Validation croisée - F1-Score: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7ac2d",
   "metadata": {},
   "source": [
    "## 13. Optimisation des hyperparamètres (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509756b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 13.1\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, None],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "# grid_search = GridSearchCV(\n",
    "#     RandomForestClassifier(random_state=42),\n",
    "#     param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='f1',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
    "# print(\"Meilleur score CV:\", grid_search.best_score_)\n",
    "# best_rf = grid_search.best_estimator_\n",
    "# best_rf_pred = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a30039",
   "metadata": {},
   "source": [
    "## 14. Analyse des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686bb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 14.1\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# # Exemple: matrice de confusion pour le meilleur modèle (remplacez best_rf_pred)\n",
    "# # cm = confusion_matrix(y_test, best_rf_pred)\n",
    "# # plt.figure(figsize=(8, 6))\n",
    "# # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "# #             xticklabels=['Non-Trending', 'Trending'],\n",
    "# #             yticklabels=['Non-Trending', 'Trending'])\n",
    "# # plt.title('Matrice de Confusion - Meilleur Modèle')\n",
    "# # plt.ylabel('Valeurs Réelles')\n",
    "# # plt.xlabel('Prédictions')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05fb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 14.2\n",
    "# # Identifier des exemples mal classifiés (adapter selon le modèle choisi)\n",
    "# # errors_mask = (y_test != best_rf_pred)\n",
    "# # error_indices = X_test[errors_mask].index\n",
    "# # print(\"Exemples de vidéos mal classifiées:\")\n",
    "# # for idx in list(error_indices)[:5]:\n",
    "# #     real_label = y_test.loc[idx]\n",
    "# #     predicted_label = best_rf_pred[list(error_indices).index(idx)]  # à adapter si nécessaire\n",
    "# #     print(f\"Index {idx}: Réel={real_label}, Prédit={predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7338b06f",
   "metadata": {},
   "source": [
    "## 15. Sauvegarde & conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE ICI - Section 15.1\n",
    "# import joblib\n",
    "# # Remplacez 'best_rf' / 'scaler' par vos objets\n",
    "# # joblib.dump(best_model, 'best_youtube_classifier.pkl')\n",
    "# # joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "# # print(\"Modèle et scaler sauvegardés avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7eddb3",
   "metadata": {},
   "source": [
    "### Conclusions à rédiger\n",
    "\n",
    "1. **Meilleur modèle**  \n",
    "   - Modèle: *[À compléter]*  \n",
    "   - Performances: *[À compléter]*  \n",
    "   - Raisons: *[À compléter]*\n",
    "\n",
    "2. **Variables les plus importantes**  \n",
    "   - *[À compléter]*\n",
    "\n",
    "3. **Limitations**  \n",
    "   - *[À compléter]*\n",
    "\n",
    "4. **Améliorations suggérées**  \n",
    "   - *[À compléter]*\n",
    "\n",
    "5. **Apprentissages**  \n",
    "   - *[À compléter]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c6e844",
   "metadata": {},
   "source": [
    "---\n",
    "## Guide de testing pour les étudiants\n",
    "\n",
    "**Comment tester vos implémentations :**\n",
    "1. **Vérifications de base** : `.shape`, `.info()`, `.head()`  \n",
    "2. **Validation des features** : pas de NaN, ratios entre 0 et 1, plages temporelles correctes  \n",
    "3. **Validation des modèles** : prédictions binaires {0,1}, longueurs cohérentes, comparaisons rigoureuses  \n",
    "4. **Tests de cohérence** : scores réalistes, F1 entre précision et rappel, impact de la normalisation  \n",
    "5. **Debugging** : augmenter `max_iter` si nécessaire, vérifier entrées/sorties et dimensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
